---
title: "Introduction to transport data science"
subtitle: '<br/>Practical'
author: "Robin Lovelace"
date: 'University of Leeds `r # Sys.Date()()`<br/><img class="img-footer" alt="" src="https://comms.leeds.ac.uk/wp-content/themes/toolkit-wordpress-theme/img/logo.png">'
output:
  github_document:
    number_sections: true
bibliography: ../tds.bib
---


Note: before you run this tutorial, ensure that you have recently updated R and RStudio on your computer.
Furthermore, you will need to have installed a number of packages, as described here: https://docs.ropensci.org/stats19/articles/stats19-training-setup.html

There is one additional package that you will need that is not available on CRAN which can be installed as follows (see [Chapter 2 of Geocomputation With R](https://geocompr.robinlovelace.net/spatial-class.html) for details, this requires the package remotes):

```r
# install.packages("remotes")
remotes::install_github("Nowosad/spDataLarge")
```

<!-- ## Agenda {-} -->

<!-- 1. Thinking about transport data science (20 min) -->
<!-- 2. Questions about the homework (10 min) -->
<!-- 3. Practical 2 (2.5 hrs) -->


# Thinking about (transport) data science 

- Based on the contents of the lecture, come up with *your own* definition of data science
- How do you see yourself using data science over the next 1 year, 5 years, 20 years
- What do you hope to get out of it personally?
- Bonus: think of a question about a transport system you know well and how data science could help answer it, perhaps with reference to a sketch like that below

#### How much potential is there for cycling across the transport network? {-}

![](https://user-images.githubusercontent.com/1825120/127524923-7d9f5511-84a6-430b-8de9-a603a5524f39.png)

# Questions about homework

1. Reproduce this script: https://github.com/ITSLeeds/pct/blob/master/inst/test-setup.R
2. Work through the transport chapter of Geocomputation with R: https://geocompr.robinlovelace.net/transport.html

# Practical 2

See https://github.com/ITSLeeds/TDS/blob/master/practicals/2-software.md


<!-- - In terms of future work in an evolving job market? -->
<!-- - In terms of the kinds of problems you want to solve? -->

<!-- ## Sketching research methods (in groups of 2-4, 30 minutes) -->

<!-- Starting with the 1000 'desire lines' dataset of Leeds, sketch-out some research ideas that cover -->

<!-- 1) Hypotheses: generate two hypotheses that are falsifiable and 2 hypotheses that are not falsifiable -->

<!-- 2) Input data: draw schematic representations of additional datasets that you could use alongside the desire lines dataset, with at least one at each of these levels: -->

<!-- - Zones -->
<!-- - Points -->
<!-- - Routes -->
<!-- - Route networks -->
<!-- - Individual -->

<!-- What temporal and spatial resolution could each one have? -->

<!-- 3) Methods: using a flow diagram (e.g. as shown below) -->

```{r schematic, echo=FALSE}
# knitr::include_graphics("https://raw.githubusercontent.com/npct/pct-team/master/flow-model/flow-diag2.png")
```

<!-- ## Practical, group computer task (30 minutes) -->

<!-- Create a github account (all). See: https://github.com -->

<!-- Building on the follow code chunk (but with no copy-and-pasting), create a data frame that contains the names, coffee habits and like/dislike of bus travel for everyone in your group (just 1 computer per group): -->


<!-- ```{r} -->
<!-- person_name = c( -->
<!--   "robin", -->
<!--   "malcolm", -->
<!--   "richard" -->
<!-- ) -->
<!-- n_coffee = c( -->
<!--   5, -->
<!--   1, -->
<!--   0 -->
<!-- ) -->
<!-- like_bus_travel = c( -->
<!--   TRUE, -->
<!--   FALSE, -->
<!--   TRUE -->
<!-- ) -->
<!-- personal_data = data.frame(person_name, n_coffee, like_bus_travel) -->
<!-- personal_data -->
<!-- ``` -->

<!-- When you are complete, add your code to https://github.com/ITSLeeds/TDS/blob/master/code-r/01-person-data.R -->

<!-- ## Learning outcomes -->

```{r, echo=FALSE}
# Identify available datasets and access and clean them
# Combine datasets from multiple sources
# Understand what machine learning is, which problems it is appropriate for compared with traditional statistical approaches, and how to implement machine learning techniques
# Visualise and communicate the results of transport data science, and know about setting-up interactive web applications
# Deciding when to use local computing power vs cloud services
```

<!-- - Articulate the relevance and limitations of data-centric analysis applied to transport problems, compared with other methods -->



## Agenda {-}

<!-- - Introduction to the module and team - 30 min -->
<!-- Each person to say  1) their name and where they are based 2) why they took the module and 3) their level of knowledge of coding. -->
1. Project set-up and using RStudio - 30 minutes
1. Getting started with transport data in the stplanr package - 30 minutes
1. Working alone through the questions on processing OD data - 1 hr
<!-- running the code in Sections 12.1 to 12.4 the Transport chapter of Geocomputation with R and answering the questions for the Bristol dataset  - 1 hr  -->
1. Bonus: Work through [Chapter 5](https://r4ds.had.co.nz/transform.html#filter-rows-with-filter) of R for Data Science

## Pre-requisites {-}

You need to have a number of packages installed and loaded.
Install the packages by typing in the following commands into RStudio (you do not need to add the comments after the `#` symbol):^[
Note: if you want to install the development version of a package from GitHub, you can do so.
Try, for example, running the following command: `remotes::install_github("ITSLeeds/pct")`
]

```{r, eval=FALSE}
install.packages("remotes")
pkgs = c(
  "nycflights13",# data package
  "pct",         # package for getting travel data in the UK
  "sf",          # spatial data package
  "stats19",     # downloads and formats open stats19 crash data
  "stplanr",     # for working with origin-destination and route data
  "tidyverse",   # a package for user friendly data science
  "tmap"         # for making maps
)
remotes::install_cran(pkgs)
remotes::install_github("nowosad/spDataLarge")
```

Load the tidyverse package as follows:

```{r}
library(tidyverse)
```

# Project set-up and tidyverse testing

1. Check your packages are up1.to-date with `update.packages()`
1. Create an RStudio project with an appropriate name for this module (e.g. `TDSmodule`)
1. Create appropriate files for code, data and anything else (e.g. images)
1. Create a script called `learning-tidyverse.R`, e.g. with the following command:

```r
dir.create("code") # 
file.edit("code/learning-tidyverse.R")
```

# Getting started with transport data

We're going to start by looking at the main types of transport data:^[
Note: if you want to get zone data for a different region you can do so, e.g. with: 
`zones = sf::read_sf("https://github.com/npct/pct-outputs-regional-notR/raw/master/commute/msoa/west-yorkshire/z.geojson")`
]

In this section we will look at basic transport data in the R package **stplanr**.

Attach the `tidyverse`, `stplanr` and `sf` packages as follows:

```{r}
library(tidyverse)
library(stplanr)
library(sf)
```

The `stplanr` package contains some data that we can use to demonstrate principles in Data Science, illustrated in the Figure below. Source: Chapter 1 of R for Data Science [@grolemund_r_2016] [available online](https://r4ds.had.co.nz/introduction.html).

![](https://d33wubrfki0l68.cloudfront.net/571b056757d68e6df81a3e3853f54d3c76ad6efc/32d37/diagrams/data-science.png)
```{r}
# import
od_data = stplanr::od_data_sample
```

```{r}
# tidy
od_data = od_data %>%
  rename(walk = foot)
```


```{r}
# transform
od_data_walk = od_data %>% 
  filter(walk > 0) %>% 
  select(geo_code1, geo_code2, all, car_driver, walk) %>% 
  mutate(proportion_walk = walk / all, proportion_drive = car_driver / all)
```

```{r}
# visualise
plot(od_data_walk)
```

```{r}
# model
model1 = lm(proportion_walk ~ proportion_drive, data = od_data_walk)
od_data_walk$proportion_walk_predicted = model1$fitted.values
```

```{r}
# visualise
ggplot(od_data_walk) +
  geom_point(aes(proportion_drive, proportion_walk)) +
  geom_line(aes(proportion_drive, proportion_walk_predicted))
```

```{r}
# transform
# ...
```

Exercises

1. What is the class of the data in `od_data`?
1. Subset (filter) the data to only include OD pairs in which at least one person (`> 0`) person walks (bonus: on what % of the OD pairs does at least 1 person walk?)
2. Calculate the percentage who cycle in each OD pair in which at least 1 person cycles
3. Is there a positive relationship between walking and cycling in the data?
4. Plot the zones representing the `geo_code` variables in the OD data
5. Bonus: use the function `od2line()` in to convert the OD dataset into geographic desire lines

```{r, echo=FALSE, eval=FALSE}
#1
class(od_data)
```

```{r, echo=FALSE, eval=FALSE}
#2 
od_data_walk = od_data %>% 
  filter(walk > 0)
nrow(od_data_walk) / nrow(od_data)
```

```{r, echo=FALSE, eval=FALSE}
#3
od_data = od_data %>% 
  filter(bicycle > 0) %>% 
  mutate(perc_cycle = (bicycle/all) * 100)
```

```{r, echo=FALSE, eval=FALSE}
#4
od_data_new = od_data %>% 
  filter(walk > 0, bicycle>0 ) %>% 
  select(bicycle, walk, all) 

model = lm(walk ~ bicycle, weights = all, data = od_data_new)
od_data_new$walk_predicted = model$fitted.values

ggplot(od_data_new) +
  geom_point(aes(bicycle, walk, size = all)) +
  geom_line(aes(bicycle, walk_predicted))
```

```{r, echo=FALSE, eval=FALSE}
#5
zones = sf::read_sf("https://github.com/npct/pct-outputs-regional-notR/raw/master/commute/msoa/west-yorkshire/z.geojson")
zones_leeds = zones %>% 
  filter(lad_name == "Leeds")
plot(zones_leeds$geometry)
```

```{r, echo=FALSE, eval=FALSE}
#6
desire_lines = od2line(flow = od_data, zones)
plot(desire_lines)
```

# Processing origin-destination data in Bristol

This section is based on Chapter 12 of Geocomputation with R: https://geocompr.robinlovelace.net/transport.html

The task is to reproduce the results shown in that chapter on your own computer.
Some code to get started on a subset of the data is shown below.

Start with a medium-sized dataset:

```{r}
# import
od = spDataLarge::bristol_od
head(od)
```

```{r}
# tidy
zones = spDataLarge::bristol_zones
zones = zones %>% 
  mutate(local_authority = word(string = name, 1))
plot(zones %>% select(local_authority), key.pos = 1)
```

```{r, eval=FALSE, echo=FALSE}
# Find central data
# bristol_centre = geo_code("bristol")
#> [1] -2.597298 51.453802
```

```{r}
# transform
bristol_sf = tmaptools::geocode_OSM("bristol", as.sf = TRUE, return.first.only = T, geometry = "point")
mapview::mapview(bristol_sf)
bristol_buffer_10km = geo_buffer(bristol_sf, dist = 10000)
zones_central = zones[bristol_buffer_10km, , op = sf::st_within]
# visualise
mapview::mapview(zones_central)
```


```{r}
# transform
od_central = od %>%
  filter(o %in% zones_central$geo_code) %>% 
  filter(d %in% zones_central$geo_code) 
nrow(od_central) / nrow(od)
desire_lines = od2line(od_central, zones_central)
desire_lines$distance_direct_m = as.numeric(st_length(desire_lines))
desire_lines = desire_lines %>% 
  mutate(proportion_active = (bicycle + foot) / all)
```

```{r, fig.show='hold', out.width="40%"}
# visualise
ggplot(desire_lines) +
  geom_point(aes(distance_direct_m, proportion_active))
ggplot(desire_lines) +
  geom_point(aes(distance_direct_m, proportion_active, size = all), alpha = 0.3)
```

```{r}
# model/visualise
m1 = lm(proportion_active ~ 
          distance_direct_m + I(distance_direct_m^2),
        data = desire_lines)
desire_lines = desire_lines %>% 
  mutate(
    new_active_travel = m1$fitted.values * car_driver,
    new_total_active = new_active_travel + bicycle + foot,
    new_proportion_active = new_total_active / all
    ) %>% 
  arrange(proportion_active)
ggplot(desire_lines) +
  geom_point(aes(distance_direct_m, proportion_active, size = all), alpha = 0.3) +
  geom_point(aes(distance_direct_m, new_proportion_active, size = all), alpha = 0.3, colour = "blue")

```

```{r}
# visualise
ggplot(desire_lines) +
  geom_sf(aes(colour = new_proportion_active, alpha = all))
```

```{r}
library(tmap)
tm_shape(desire_lines) +
  tm_lines(palette = "-viridis", breaks = c(0, 5, 10, 20, 40, 100) / 100,
    lwd = "all",
    scale = 9,
    title.lwd = "Number of trips",
    alpha = 0.6,
    col = c("proportion_active", "new_proportion_active"),
    title = "Active travel (%)"
  ) +
  tm_scale_bar()

```

# Processing medium sized data and basic visualisation

This section will use content from Chapter 5 of the R for Data Science book [@grolemund_data_2016].

- Read [section 5.1](https://r4ds.had.co.nz/transform.html#filter-rows-with-filter) of R for Data Science and write code that reproduces the results in that section in the script `learning-tidyverse.R`

Your script will start with something like this:

```{r}
library(tidyverse)
library(nycflights13)
```

- Take a random sample of 10,000 flights and assign it to an object with the following line of code:

```{r}
library(nycflights13)
flights_sample = sample_n(flights, 1e4)
unique(flights$carrier)
```

- Find the unique carriers with the `unique()` function

- Create an object containing flights from United, American, or Delta, and assign it to `f`, as follows:

```{r}
f = filter(flights, grepl(pattern = "UA|AA|DL", x = carrier))
f2 = filter(flights, grepl(pattern = "UA", x = carrier) |
             grepl(pattern = "AA", x = carrier) |
             grepl(pattern = "DL", x = carrier)
           )
f3 = filter(flights, str_detect(carrier, "UA|AA|DL"))
```

- Create plots that visualise the sample flights, using code from Chapter 3 of the same book, starting with the following plot:

```{r, message=FALSE, warning=FALSE}
ggplot(f) +
  geom_point(aes(air_time, distance))
```

- Add transparency so it looks like this (hint: use `alpha =` in the `geom_point()` function call):

```{r, echo=FALSE}
ggplot(f) +
  geom_point(aes(air_time, distance), alpha = 0.1)
```

- Add a colour for each carrier, so it looks something like this:

```{r}
ggplot(f) +
  geom_point(aes(air_time, distance, colour = carrier), alpha = 0.5)
```

- Bonus 1: find the average air time of those flights with a distance of 1000 to 2000 miles

- Bonus 2: use the `lm()` function to find the relationship between flight distance and time, and plot the results (start the plot as follows, why did we use `na.omit()`? hint - find help with `?na.omit()`):

```{r}
f = na.omit(f)
m = lm(air_time ~ distance, data = f)
f$pred = m$fitted.values
```

```{r, echo=FALSE}
ggplot(f) +
  geom_point(aes(air_time, distance, colour = carrier), alpha = 0.5) +
  geom_line(aes(pred, distance))
```

# Homework

1) create a reproducible document 

- Create an Rmarkdown file with the following command:

```r
file.edit("learning-tidyverse.Rmd")
```

- Take a read of the guidance on RMarkdown files online and in the following location (or search online for the 'RMarkdown cheatsheet'):

```
Help > Cheatsheets > RMarkdown
```

- Put the code you generated for `tidyverse.R` into the Rmd file and knit it

- Bonus: create a GitHub repo and publish the results of of your work (hint: putting `output: github_document` may help here!)

2) Work-through the remaining exercises of the first sections in R4DS chapters 3 and 5
  - Write and R script, with comments, to show your working (and prove you've done it!)
  
```{r, include=FALSE}
library(tidyverse)
mpg
ggplot(mpg) +
  geom_point(mapping = aes(hwy, cyl, col = drv ))
library(nycflights13)
names(flights)
?flights
# Were delayed by at least an hour, but made up over 30 minutes in flight
# part 1:
delayed_hour = flights %>% 
  filter(dep_delay > 60)
nrow(delayed_hour) / nrow(flights)
# part 2: calculate length of delay
flight_delays = flights %>% 
  mutate(delay = dep_delay - arr_delay)
summary(flight_delays$delay)

# part 3:
result = flight_delays %>% 
  filter(dep_delay > 60 & delay > 30)  
nrow(result)

summary(is.na(flights$arr_delay))

# base R approach
sel_delayed = flights$dep_delay > 60 &
  !is.na(flights$dep_delay)
sel_arrive = flights$arr_delay < 30 &
  !is.na(flights$arr_delay)
class(sel_arrive)
sel_combined = sel_arrive & sel_delayed
sum(sel_combined)
result2 = flights[sel_combined, ]
nrow(result2)
```
  

3) Create an RMarkdown file containing reproducible code outlining what you learned today

4) Try mapping OD data for West Yorkshire in preparation for the next practical on routing
